---
title: "Diabetes Prediction model: NHANES data 2013-2014" 
author: "Hannah Rosenblum, James Ng, Purnima Sharma"
output:
  pdf_document:
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
header-includes:
- \usepackage{fancyhdr}
- \usepackage{lipsum}
- \pagestyle{fancy}
- \fancyhead[R]{\thepage}
- \fancypagestyle{plain}{\pagestyle{fancy}}
--- 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, results = 'asis')
```

\newpage

```{r}
library(RNHANES)
library(tidyverse)
library(summarytools)
library(leaps)
library(readr)
library(caret)
library(ggplot2)
library(patchwork)
library(mgcv)
library(nlme)
library(dplyr)
library(plyr)
library(AppliedPredictiveModeling)
library(dplyr)
library(scales)
library(pROC)
#library(MASS) 
#library(klaR)
library(forcats)
library(visdat)
library(glmnet)
library(mlbench)
library(pROC)
library(pdp)
library(vip)
library(rpart.plot)
library(ranger)
library(randomForest) 
library(gbm)
library(e1071) 	
library(kernlab) 	
```

# Introduction

This project aims to study any association between diabetes and several covariates in participants ages 1 and older, using NHANES data, and selecting an optimal prediction model among linear, non-linear, parametric and non-parametric models. The main objective is building a binary classification model with supervised learning. Certain factors of special interest were any association with participant’s race, age, cholesterol and lifestyle factors, among others. Data was extracted for the year 2013 - 2014 from the cdc.gov website, https://wwwn.cdc.gov/nchs/nhanes/continuousnhanes/default.aspx?BeginYear=2013. 

## Data description

Specifically, association was assessed between diabetes and the following covariates:

* Gender: Participant's gender (male or female)
* Age: Age at screening, with possible values of 0 to 79, or 80+ (years)
* Race: 6 categories for race include Mexican American, other Hispanic, White, Black, Asian and other. 
* bmi: body mass index (kg/m^2) 
* hdl: High-density lipoprotein (mg/dL)
* Blood pressure (mm Hg): Both systolic and diastolic, first-round measurements
* waist: Waist circumference measurement (cm)
* Sedentary activity (lifestyle, minutes): time spent sitting in a given day, not including sleeping.
* Education level: highest degree of adults 20+ years of age, with 7 categories. 
* Marital status: Categories include married, widowed, divorced, separated, never married, living with partner, refused, and don't know
* Depression: severity on a scale of 0 to 3 treated as a continuous variable, with 0 as not at all depressed
* Sleep: amount of sleep in hours on a given night on weekdays or workdays

The outcome of "diabetes" dependent-variable was based on classification of the participants into two groups of those with diabetes and those who did not have diabetes. Individuals answered the question "other than during pregnancy, have you ever been told by a doctor or health professional that you have diabetes or sugar diabetes?", and were classified as having diabetes if they answered yes. 

## Motivation

Motivation was provided by the fact that diabetes is one of the major leading causes of death in the United States. As stated by the CDC site's National Diabetes Statistics Report of 2020, 34.2 million Americans are diabetic, while 7.3 million were undiagnosed. Furthermore, increase in type 2 diabetes among children is a growing concern according to the CDC. With prevalence of diabetes and prediabetes on the rise, it was of interest to find factors that might affect the diabetes status. Later years post-2013 were tried for the data, however were unavailable for the variables of interest possibly due to continuing updates. 

## Data cleaning

After extracting and merging the necessary files by participant’s Id number, variables of interest were retained in a dataframe. Gender, race, education level, marital status  and the response variable Diabetes were converted to factors from numeric data type. Missing entries for the response of diabetes status were removed. 185 “borderline “ reported cases, 5 with “don’t know” responses and 1 with “refused” response were also removed given the small scale of these categories, which accounted for less than 2% of the data, and in order to focus on the majority of binary responses of presence or absence of diabetes. The cleaned dataset contained 9,578 observations of 18 variables, including the binary outcome variable diabetes. 

```{r}
data_files <- nhanes_load_data(file_name = "DIQ_H", year = "2013-2014")

data_files <- data_files %>% 
  left_join(nhanes_load_data("HDL_H", "2013-2014"), by = "SEQN") %>%
  left_join(nhanes_load_data("INS_H", "2013-2014"), by = "SEQN") %>%
  left_join(nhanes_load_data("TRIGLY_H", "2013-2014"), by = "SEQN") %>% 
  left_join(nhanes_load_data("DEMO_H", "2013-2014"), by = "SEQN") %>% 
  left_join(nhanes_load_data("BMX_H", "2013-2014"), by = "SEQN") %>% 
  left_join(nhanes_load_data("OGTT_H", "2013-2014"), by = "SEQN") %>% 
  left_join(nhanes_load_data("BPX_H", "2013-2014"), by = "SEQN") %>% 
  left_join(nhanes_load_data("PAQ_H", "2013-2014"), by = "SEQN") %>% 
  left_join(nhanes_load_data("DPQ_H", "2013-2014"), by = "SEQN") %>% 
  left_join(nhanes_load_data("SLQ_H", "2013-2014"), by = "SEQN")

raw_data <- data_files %>% 
  select(SEQN, RIAGENDR, RIDAGEYR, RIDRETH3, BMXBMI, LBDHDD, LBDLDL, LBXTR, LBXIN, LBXGLT, BPXSY1, BPXDI1, BMXWAIST,  PAD680, DMDEDUC2, DMDMARTL, DPQ020, SLD010H,  DIQ010) 

raw_data <- raw_data[raw_data$DIQ010 != 3 & raw_data$DIQ010 != 7 & raw_data$DIQ010 != 9, ] %>%  mutate(RIAGENDR = as_factor(RIAGENDR), RIDRETH3 = as_factor(RIDRETH3),DMDEDUC2 = as_factor(DMDEDUC2), DMDMARTL = as_factor(DMDMARTL), DIQ010 = as_factor(DIQ010)) %>% 
  drop_na(DIQ010)
 
 colnames(raw_data) <- c("ID", "gender", "age", "race", "bmi", "hdl", "ldl", "triglyceride", "insulin", "glucose", "bp_systolic","bp_diastolic", "waist","lifestyle", "education", "married", "depression", "sleep", "diabetes") 
 
 levels(raw_data$diabetes)[1] <- "yes"
 levels(raw_data$diabetes)[2] <- "no"
```

# EDA

Exploratory data analysis was performed for all 18 initial variables, including the outcome of response, using density plots and bar graphs. Summary statistics were analyzed for all variables, to get an overview of the data and check for extent of missing values. Density plots were used to check for relationships between diabetes and other numeric variables. Categorical variables were visualized separately, using bar graphs instead. 

## summary statistics

```{r}
st_options(plain.ascii = FALSE,       
           style = "rmarkdown", 
           dfSummary.silent = TRUE,        
           footnote = NA,          
           subtitle.emphasis = FALSE)      

dfSummary(raw_data[,-1], valid.col = FALSE)

raw_data <- raw_data[-c(7:10)]
```

As noted above in the summary table, several of the variables for laboratory data had high missing values. The variables ldl, triglyceride, insulin and 2hr glucose-test had close to 70% of the data missing. In an effort to retain a large enough sample size, the four variables were not retained for further analysis in this project.  

## Density plots

```{r, fig.height=4}

theme1 <- transparentTheme(trans = .4)
trellis.par.set(theme1)

raw_data <- raw_data %>% 
  select(married, everything()) %>% 
  select(education, everything()) %>% 
  select(race, everything()) %>% 
  select(gender, everything()) %>% 
  select(ID, everything())

featurePlot(x = raw_data[, 6:14], 
            y = raw_data$diabetes,
            scales = list(x = list(relation = "free"), 
                          y = list(relation = "free")),
            plot = "density", pch = "|", 
            auto.key = list(columns = 2))
```

Density plots of several numeric covariates showed differences in distributions of the two classes. Plots of systolic blood pressure, waist circumference measurement, age, and body mass index seemed significantly different between those with diabetes and those without. Most significant difference seemed to be among different age groups, with a density curve of responses with no diabetes showing right-skewness, and those with diabetes skewed to the left along with a strong shift towards higher age. 

## Bar plots

```{r, fig.show ='hide'}
diabetes_gender = ggplot(raw_data, 
       aes(x = diabetes, 
           fill = factor(gender,
                         levels = c("1", "2"),
                         labels = c("male", "female")))) + 
  geom_bar(position = position_dodge(preserve = "single")) +
   scale_fill_brewer(palette = "Set2") +
  labs(fill = "gender")

diabetes_race = ggplot(raw_data, 
       aes(x = diabetes, 
           fill = factor(race,
                         levels = c("1", "2", "3", "4", "6", "7"),
                         labels = c("Mexican American", "Other Hispanic", "White", "Black", "Asian", "Other")))) + 
  geom_bar(position = position_dodge(preserve = "single")) +
   scale_fill_brewer(palette = "Set2") +
   labs(fill = "race")

diabetes_education = ggplot(raw_data, 
       aes(x = diabetes, 
           fill = factor(education,
                         levels = c("1", "2", "3", "4", "5"),
                         labels = c("< 9th grade", "9 - 11 grade", "H.S./GED", "Some college", "College graduate")))) + 
  geom_bar(position = position_dodge(preserve = "single")) +
   scale_fill_brewer(palette = "Set2") +
   labs(fill = "education")

diabetes_married = ggplot(raw_data, 
       aes(x = diabetes, 
           fill = factor(married,
                         levels = c("1", "2", "3", "4", "5", "6"),
                         labels = c("Married", "Widowed", "Divorced", "Separated", "Never married", "Living with partner")))) + 
  geom_bar(position = position_dodge(preserve = "single")) +
   scale_fill_brewer(palette = "Set2") +
    labs(fill = "married")

(diabetes_gender + diabetes_race)  / (diabetes_education + diabetes_married) 
```

Bar plots, not shown, were analyzed for categorical variables gender, race ,education level, and marital status. Presence of diabetes did not seem to be gender-dependent, and with slight differences based on education level. Proportion of positive diabetes cases did seem to vary among different races, and based on marital status. There seemed to be a significantly higher proportion of non-diabetics among individuals who were never-married or divorced.

Finally, paired partition plots were also examined for several variables using training data, to analyze misclassification rate. Methods using linear discriminant analysis, and non-linear boundaries such as quadratic discriminant analysis and Naive Bayes method were used, giving similar results in terms of error rates. Shown below is partition plots using Naive Bayes method for paired visuals on age, bmi, hdl, systolic blood pressure, and waist.

## Partition plots

```{r}
set.seed(1)
rowTrain <- createDataPartition(y = raw_data$diabetes,
                                p = 0.7,
                                list = FALSE)

# Exploratory analysis: LDA/QDA/NB based on every combination of two variables

# klaR::partimat(diabetes ~ age + bmi +  hdl + bp_systolic + waist, 
#        data = raw_data, subset = rowTrain, method = "lda")

# klaR::partimat(diabetes ~ age + bmi + hdl  + bp_systolic + waist, 
#         data = raw_data, subset = rowTrain, method = "qda")

 klaR::partimat(diabetes ~ age + bmi + hdl  + bp_systolic + waist, 
          data = raw_data, subset = rowTrain, method = "naiveBayes")
```

## Missing data

 The four Variables with high proportions of missing data, most of which were close to 70%,  were removed. For the remaining variables with missing values, most were close to 25%, except marital status, education and depression level, which were approximately 40% missing. Assuming that the data was missing at random, and that single imputation might lead to bias and might not preserve relationships between variables; for those reasons imputation was not considered and the missing values were removed. The final sample consisted of 4,246 participants, still a fairly large dataset.

```{r}
# Missing data omitted
diabetes_data <- na.omit(raw_data)

# Omit low-count subcategories
diabetes_data <- na.omit(diabetes_data) %>%
  filter(married != "77") %>%
  filter(education != "7") %>%
  filter(education != "9") %>%
  droplevels()

set.seed(1)
trainRows <- createDataPartition(diabetes_data$diabetes, p = 0.8, list = FALSE)


# training data
x <- diabetes_data[trainRows ,-c(1, 15)]
y <- diabetes_data$diabetes[trainRows]

# test data
x2 <- diabetes_data[-trainRows ,-c(1, 15)]
y2 <- diabetes_data$diabetes[-trainRows]

# Setup CV method
ctrl <- trainControl(method = "cv",
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)
```

# Models

## Methods

Given a fairly large sample size the data was partitioned into train and test for prediction accuracy analysis, with 80% to 20% split. Several model-building techniques were used to predict the risk of diabetes using the 15 variables associated with it. Gender, age, race, bmi, hdl, systolic and diastolic blood pressure, waist circumference, lifestyle, education, marital status, depression and sleep were used as the predictor variables in the model building process. Given that the outcome was binary, generalized linear and non-linear methods such as logistic regression and discriminant analysis were tried, along with ensemble methods for trees, and the SVM (support vector machines) linear and non-linear boundary methods. For comparability of cross-validation performance, all models were fitted using the `caret` package. Built-in 10-fold cross validation method was used to get the area under the curves for comparisons, along with the summary statistics of performances on training data. 
 

Due to ease of interpretability and the binary nature of the outcome, glm (logistic regression) and penalized logistic regression models were fitted to assess linear decision boundaries. Various combinations of the two tuning parameters were tried for the penalized logistic model to find the specific values that worked well for the given data. Generalized additive model (GAM) was considered but not used due to the length of time for its execution. Non-linear MARS model, with similar performance to GAM, was retained. Various combinations for tuning grid were tried to get its optimal performance.    

While no assumptions are needed for the predictors in linear logistic model, for discriminant analysis it is assumed that the predictors follow a normal  distribution within each group of response, and that the variance-covariance matrix for response classes are the same for linear model (LDA), or could be different for non-linear QDA. Since four of the covariates in the dataset were categorical, these models were tried but excluded from analysis, also for the fact that these models work well for well-separated classes which was not apparent in the EDA. Under the assumption that features are independent within each class, Naives Bayes method (NB) was used due to its ability to handle mixed covariates, and due to its slightly better performance than LDA and QDA in terms of area under the ROC (receiver operating characteristic curve).

```{r}
# LINEAR
## glm
set.seed(1)

model.glm <- train(x = x, 
                   y = y,
                   method = "glm",
                   metric = "ROC",
                   trControl = ctrl)

## Penalized Logistic regression
glmnGrid <- expand.grid(.alpha = seq(0, 1, length = 6),
                        .lambda = exp(seq(-8, -2, length = 10)))
set.seed(1)

model.glmn <- train(x = data.matrix(x),
                    y = y,
                    method = "glmnet",
                    tuneGrid = glmnGrid,
                    metric = "ROC",
                    trControl = ctrl)

# NON-LINEAR
## MARS
set.seed(1)

model.mars <- train(x = x,
                    y = y,
                    method = "earth",
                    tuneGrid = expand.grid(degree = 1:3, 
                                           nprune = 2:15),
                    metric = "ROC",
                    trControl = ctrl)

## NB
set.seed(1)

nbGrid <- expand.grid(usekernel = c(FALSE,TRUE),
                      fL = 1, 
                      adjust = seq(.2, 2.5, by = .2))

model.nb <- train(x = x,
                  y = y,
                  method = "nb",
                  tuneGrid = nbGrid,
                  metric = "ROC",
                  trControl = ctrl)

# Tree-based ENSEMBLE
## Adaboost
gbmA_grid <- expand.grid(n.trees = c(2000,3000,4000),
                         interaction.depth = 1:6,
                         shrinkage = c(0.001,0.003,0.005),
                         n.minobsinnode = 1)

set.seed(1)

gbmA.fit <- train(diabetes ~ . , 
                  diabetes_data, 
                  subset = trainRows, 
                  tuneGrid = gbmA_grid,
                  trControl = ctrl,
                  method = "gbm",
                  distribution = "adaboost",
                  metric = "ROC",
                  verbose = FALSE)

ggplot(gbmA.fit, highlight = TRUE) +
  labs(title = "AdaBoost")

# SVML
set.seed(1)

svml.fit <- train(diabetes ~ . , 
                  data = diabetes_data[trainRows,], 
                  method = "svmLinear2",
                  tuneGrid = data.frame(cost = exp(seq(0,2,len = 100))),
                  metric = "ROC",
                  trControl = ctrl)

```


Models using non-parametric approach such as trees were also fitted using ensemble methods, which help improve prediction accuracy. Wisdom of crowds (bagging and random forest), and wisdom of weighted crowds of experts (Boosting) were the ensemble methods used. Single trees were not considered due to lack of predictive accuracy when compared to ensemble approach.  For a single tree, a small change in data could cause a significant amount of change in the final estimated tree. For those reasons, it was left out. Random forest, bagging, boosting, and weighted boosting using `adaboost` were tried. Boosting model using `adaboost`, which minimizes the  exponential loss function, was retained among the ensemble models due to its relatively better performance.   

Lastly, support vector classifiers were also fitted, with linear and non-linear decision boundaries. Tuning grids were finalized after analyzing outputs of several combinations. The two models were compared using the ROC curve as a metric, with similar results. Nonlinear model was fitted using both the tuning parameters, giving a two-dimensional tuning grid. For that reason, a simpler linear model was selected for further comparison, considering the time of execution also as a deciding factor between the two models. Initially built using `kernlab` package, with predicted class probabilities requested the model iterations were showing as a part of the output. Using the `e1071` library instead to run the svm linear model corrected the problem.       
Neural networks were not considered due to their blackbox approach, which would result in non-transparency.


## Model comparison

```{r}
res <- resamples(list(GLM = model.glm, 
                      GLMNET = model.glmn, 
                      MARS = model.mars, 
                      NB = model.nb,
                      gbmA = gbmA.fit,
                      svml = svml.fit))

#summary(res)
bwplot(res, metric = "ROC")
```

Comparing the models, their summary and boxplots showed that GLM model gave the highest median of 0.828 for ROC, a characteristic for evaluating performance based on sensitivity and specificity of a model at different thresholds for classification of response. Although the mean was marginally higher for `adaboost` model, simpler model was selected as the final model for ease of interpretability and as a better fit for a noisy data. Support vector machine linear model had the worst performance when compared to the other five final models. Based on these resampling comparisons and using ROC as our metric for model selection, GLM was chosen as the final model, and its prediction performance was then evaluated on test data.

## Final model: GLM

```{r, results='markup'}
# glm
set.seed(1)

model.glm <- train(x = x, 
                   y = y,
                   method = "glm",
                   metric = "ROC",
                   trControl = ctrl)

summary(model.glm)
```

Summary statistics of the model shows age, hdl, waist and education level of college versus below 9th grade as highly significant predictors of diabetes. Gender, race being American whites versus Mexicans, bmi, diastolic blood-pressure, and education level in general are also shown as significant predictors at 5% significance level. For instance, having attended college versus only up to 9th grade education level, changes the log odds of not having diabetes by 0.87, or by 2.4 times.

Model:

log(odds of no diabetes)= = 7.926 - 0.34 female - 0.049 age + 0.47 white + 0.065 bmi + 0.027 hdl + 0.011 diastolic - 0.0667 waist + 0.548 High_School+ 0.484 Some_college + 0.866 College_graduate + 0.8 living_with_partner - 0.0347 sleep        


## Model prediction performance

```{r, results='markup'}
# glm
set.seed(1)

model.glm <- train(x = x, 
                   y = y,
                   method = "glm",
                   metric = "ROC",
                   trControl = ctrl)

## Test data classification performance: confusion matrix at 0.5 cut-off
test.pred.prob <- predict(model.glm, newdata = x2,
                           type = "prob")[,2]
test.pred <- rep("yes", length(test.pred.prob))
test.pred[test.pred.prob > 0.5] <- "no"

confusionMatrix(data = as.factor(test.pred),
                reference = diabetes_data$diabetes[-trainRows],
                positive = "no")
```

Based on the confusion matrix at 0.5 threshold level, the accuracy of the model was 0.8762, which was same in value to "No Information Rate". This indicates that the classification was not that meaningful at the selected level of 0.5 threshold.  `Kappa`, which accounts for agreement by chance between observed and predicted classification, was also low at 0.1769 indicating that the probability of agreement could be by chance and not necessarily due to correct predictions. 

To further analyze prediction performance at other threshold cutoffs, ROC curve with range of threshold values between 0 and 1 was plotted. 

```{r}
set.seed(1)

model.glm <- train(x = x, 
                   y = y,
                   method = "glm",
                   metric = "ROC",
                   trControl = ctrl)

## Test data performance: ROC curve
glm.pred <- predict(model.glm, newdata = x2, type = "prob")[,2]
roc.glm <- roc(y2, glm.pred)
plot(roc.glm, legacy.axes = TRUE, print.auc = TRUE)
plot(smooth(roc.glm), col = 4, add = TRUE)
```

The high area under the curve at 0.842 indicates that the model seemed to perform well on classifying the test data for the given dataset. 

## Limitations
 The models were limited in their accuracy due to the imbalance of the dataset.A larger dataset would have been needed to correct the skewness of class distribution, by including a greater range of data time-periods. Additionally, including greater set of covariates of potential influence, such as work conditions, exposure to environmental pollutants, etc. would also have helped to formulate a more precise model. Another limitation of models were that only the complete cases were used in the building process, under the assumption that data was missing at random. That might not have been the case for all missing data, for example the body weight data for participants who had limb amputations were set to missing. This factor was not a part of this data. Finally, extremely small sample sizes in several subcategories, which had to be excluded, were not handled well by the models. 

# Conclusion
For the given dataset, the final model selected performed fairly well in predicting the test-data responses, when evaluated based on area under the ROC curve. The findings were in support of the expectation that simple linear models do well with noisy data, which could be the issue with epidemiological data. A lot more laboratory data was missing than expected and the surveys were based on recollection, which could have lead to recall bias and under-reporting. These factors could have been the cause of noisy data that the other models were unable to account for properly.    

 The data included both type 1 and type 2 diabetes records without segregating the two groups. It was unfortunate to realize that the age distinctions between the two forms of the disease are disappearing; what was known as adult-onset diabetes can begin during childhood.  
 
 Significant association between diabetes and age, waist circumference as an indicator of weight, diastolic blood pressure and high density lipids was as expected, which has been a well-documented fact at this point. Relevance of college education and marital status were unexpected.
 
 There is high rate of missingness in epidemiological studies and surveys than would be expected, making any inferences and predictions to be drawn from them tricky at best. This dataset showed that sometimes more involved and complicated models do not always mean a better model, a critical element to remember when model building and analyzing data from a study.
 


